# データ処理ツール刷新計画

## 現状分析

### 課題

- Pythonスクリプトでのテーブル作成手法が統一されていない（直接・SQLite経由）
- データ加工処理がAccessとSQLiteで分散
- データ更新に20分要している
- BOMデータ60万件の取り込みができていない
- 定数（const）管理ができておらず、パスの重複記載

### 対象データ

- ファイル数：約50個（txt・csv・xlsx）
- データ量：大容量（最大200MB超のファイルあり）
- 更新頻度：日次・月次

## 提案：段階的改善アプローチ

### Phase 1: 基盤整備（1-2週間）

#### 1.1 フォルダ構成の統一

```
C:\Projects_workspace\03_unified_system\
├── config/                 # 設定ファイル
│   ├── constants.py        # パス・定数管理
│   ├── database_config.py  # DB接続設定
│   └── file_mapping.yaml   # ファイル-テーブル対応
├── src/                    # ソースコード
│   ├── core/              # コア機能
│   │   ├── sqlite_manager.py
│   │   ├── file_processor.py
│   │   └── access_exporter.py
│   ├── processors/        # データ処理
│   │   ├── sap_processors/
│   │   └── transform_rules/
│   └── dashboard/         # ダッシュボード
├── data/                  # データディレクトリ
│   ├── raw/              # 生データ（SAP出力）
│   ├── sqlite/           # SQLiteDB
│   └── access/           # Access配布用
├── logs/                 # ログ
└── tests/                # テスト
```

#### 1.2 定数管理の統一

```python
# config/constants.py
from pathlib import Path

class Paths:
    PROJECT_ROOT = Path(r"C:\Projects_workspace\03_unified_system")
    RAW_DATA = PROJECT_ROOT / "data" / "raw"
    SQLITE_DB = PROJECT_ROOT / "data" / "sqlite" / "main.db"
    ACCESS_OUTPUT = PROJECT_ROOT / "data" / "access"
    
class FilePatterns:
    SAP_FILES = {
        "PLM": "GetPLMItmPlntInfo_*.txt",
        "WBS": "GetSekkeiWBSJisseki.txt",
        "BOM": "MARA_DL.csv"
    }
```

### Phase 2: データパイプライン構築（2-3週間）

#### 2.1 統一SQLite基盤

```python
# src/core/sqlite_manager.py
class SQLiteManager:
    def __init__(self, db_path):
        self.db_path = db_path
        
    def bulk_insert_from_file(self, file_path, table_name, chunk_size=10000):
        # 大容量ファイル対応の分割処理
        
    def create_indexes(self):
        # 性能向上のためのインデックス作成
        
    def export_to_access_format(self, table_name):
        # Access互換データ型での出力
```

#### 2.2 ファイル処理の自動化

```python
# src/core/file_processor.py
class FileProcessor:
    def process_daily_files(self):
        # 日次ファイルの自動処理
        
    def process_monthly_files(self):
        # 月次ファイルの自動処理
        
    def handle_large_files(self, file_path):
        # 大容量ファイルの分割処理
```

### Phase 3: 配布ツール開発（2週間）

#### 3.1 Access配布用データ生成

- SQLiteから加工済みデータをAccess形式で出力
- データ型の互換性確保
- 元テーブルは格納しない方針

#### 3.2 ダッシュボード開発

```python
# Tkinterベースのダッシュボード
class MainDashboard:
    def __init__(self):
        # メイン画面
        
    def show_data_status(self):
        # データ更新状況表示
        
    def show_error_details(self):
        # エラー詳細表示
        
    def export_reports(self):
        # レポート出力
```

## 性能改善策

### データ更新時間短縮（目標：20分→5分以下）

1. **並行処理**: ThreadPoolExecutorでファイル処理を並列化
2. **分割処理**: 大容量ファイルをチャンク単位で処理
3. **インデックス最適化**: 頻繁に使用するカラムにインデックス
4. **差分更新**: 変更があったファイルのみ処理

### BOMデータ60万件対応

```python
def process_bom_data(file_path, chunk_size=50000):
    # pandas.read_csv with chunksize
    for chunk in pd.read_csv(file_path, chunksize=chunk_size):
        # 分割処理でメモリ効率化
        process_chunk(chunk)
```

## 実装順序

### Week 1-2: 基盤整備

- [x] フォルダ構成作成
- [x] 定数管理実装
- [x] SQLiteManager基本機能

### Week 3-4: コア機能開発

- [ ] ファイル処理自動化
- [ ] 大容量データ対応
- [ ] エラーハンドリング

### Week 5-6: 配布ツール

- [ ] Access出力機能
- [ ] Tkinterダッシュボード
- [ ] テスト・デバッグ

## 既存システムとの共存

### 移行戦略

1. 新システムを`03_unified_system`として並行稼働
2. 既存の`02_access`は当面維持
3. 段階的に処理を新システムに移行
4. 動作確認後、既存システムを段階的廃止

### 軽微な既存改善

```python
# 既存スクリプトに追加可能な改善
import sys
sys.path.append(r"C:\Projects_workspace\03_unified_system\config")
from constants import Paths, FilePatterns

# パスの重複記載を解消
```

## 期待効果

- **処理時間**: 20分 → 5分以下
- **保守性**: 統一された処理基盤
- **拡張性**: 新ファイル追加の容易さ
- **信頼性**: エラーハンドリングとログ
- **配布性**: Access・ダッシュボード両対応
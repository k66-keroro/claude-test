"""
å®šæ•°ãƒ»ãƒ‘ã‚¹ç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ä½œæˆæ—¥: 2025å¹´6æœˆ24æ—¥
ç›®çš„: ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã§ä½¿ç”¨ã™ã‚‹å®šæ•°ã€ãƒ‘ã‚¹ã€è¨­å®šå€¤ã®çµ±ä¸€ç®¡ç†
"""

import os
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple


@dataclass
class Paths:
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    # ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    BASE_DIR: Path = Path("C:/Projects_workspace/03_unified_system")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    DATA_DIR: Path = BASE_DIR / "data"
    RAW_DATA_DIR: Path = DATA_DIR / "raw"
    SQLITE_DIR: Path = DATA_DIR / "sqlite"
    ACCESS_DIR: Path = DATA_DIR / "access"
    BACKUP_DIR: Path = DATA_DIR / "backup"
    
    # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    LOGS_DIR: Path = BASE_DIR / "logs"
    ERROR_LOGS_DIR: Path = LOGS_DIR / "errors"
    
    # è¨­å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    CONFIG_DIR: Path = BASE_DIR / "config"
    
    # ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    SRC_DIR: Path = BASE_DIR / "src"
    CORE_DIR: Path = SRC_DIR / "core"
    
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    TEMP_DIR: Path = BASE_DIR / "temp"
    
    @classmethod
    def create_directories(cls) -> None:
        """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        paths_to_create = [
            cls.DATA_DIR,
            cls.RAW_DATA_DIR,
            cls.SQLITE_DIR,
            cls.ACCESS_DIR,
            cls.BACKUP_DIR,
            cls.LOGS_DIR,
            cls.ERROR_LOGS_DIR,
            cls.CONFIG_DIR,
            cls.SRC_DIR,
            cls.CORE_DIR,
            cls.TEMP_DIR
        ]
        
        for path in paths_to_create:
            path.mkdir(parents=True, exist_ok=True)
    
    @classmethod
    def get_full_path(cls, relative_path: str) -> Path:
        """ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›"""
        return cls.BASE_DIR / relative_path


@dataclass
class FilePatterns:
    """å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©"""
    
    # PLMãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
    PLM_PATTERN: str = "GetPLMItmPlntInfo_*.txt"
    PLM_ENCODING: str = "shift_jis"
    PLM_DELIMITER: str = "\t"
    
    # WBSãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
    WBS_PATTERN: str = "GetSekkeiWBSJisseki.txt"
    WBS_ENCODING: str = "shift_jis"
    WBS_DELIMITER: str = "\t"
    
    # BOMãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
    BOM_PATTERN: str = "MARA_DL.csv"
    BOM_ENCODING: str = "shift_jis"
    BOM_DELIMITER: str = ","
    
    # ç”Ÿç”£ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
    PRODUCTION_PATTERN: str = "PP_DL_CSV_SEISAN_YOTEI.csv"
    PRODUCTION_ENCODING: str = "shift_jis"
    PRODUCTION_DELIMITER: str = ","
    
    # åœ¨åº«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
    INVENTORY_PATTERN: str = "dbo_æå‡ºç”¨_çµŒç†_æ»ç•™åœ¨åº«è³‡æ–™_é€šå¸¸.xlsx"
    INVENTORY_ENCODING: str = "utf-8"
    INVENTORY_SHEET_NAME: str = "Sheet1"
    
    # å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¾æ›¸
    @classmethod
    def get_all_patterns(cls) -> Dict[str, Dict[str, str]]:
        """å…¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³æƒ…å ±ã‚’è¾æ›¸ã§è¿”ã™"""
        return {
            "PLM": {
                "pattern": cls.PLM_PATTERN,
                "encoding": cls.PLM_ENCODING,
                "delimiter": cls.PLM_DELIMITER,
                "type": "txt"
            },
            "WBS": {
                "pattern": cls.WBS_PATTERN,
                "encoding": cls.WBS_ENCODING,
                "delimiter": cls.WBS_DELIMITER,
                "type": "txt"
            },
            "BOM": {
                "pattern": cls.BOM_PATTERN,
                "encoding": cls.BOM_ENCODING,
                "delimiter": cls.BOM_DELIMITER,
                "type": "csv"
            },
            "PRODUCTION": {
                "pattern": cls.PRODUCTION_PATTERN,
                "encoding": cls.PRODUCTION_ENCODING,
                "delimiter": cls.PRODUCTION_DELIMITER,
                "type": "csv"
            },
            "INVENTORY": {
                "pattern": cls.INVENTORY_PATTERN,
                "encoding": cls.INVENTORY_ENCODING,
                "sheet_name": cls.INVENTORY_SHEET_NAME,
                "type": "xlsx"
            }
        }


@dataclass
class ProcessConfig:
    """å‡¦ç†æ€§èƒ½è¨­å®š"""
    
    # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†è¨­å®š
    DEFAULT_CHUNK_SIZE: int = 50000
    LARGE_FILE_CHUNK_SIZE: int = 100000
    MEMORY_LIMIT_MB: int = 512
    
    # ä¸¦è¡Œå‡¦ç†è¨­å®š
    MAX_WORKERS: int = 4
    TIMEOUT_SECONDS: int = 300
    MAX_RETRIES: int = 3
    RETRY_DELAY: int = 2
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºé–¾å€¤
    SMALL_FILE_MB: int = 10
    MEDIUM_FILE_MB: int = 100
    LARGE_FILE_MB: int = 500
    
    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¨­å®š
    SUPPORTED_ENCODINGS: List[str] = None
    ENCODING_DETECTION_CONFIDENCE: float = 0.7
    ENCODING_SAMPLE_SIZE: int = 10240
    
    def __post_init__(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š"""
        if self.SUPPORTED_ENCODINGS is None:
            self.SUPPORTED_ENCODINGS = [
                "utf-8", "shift_jis", "cp932", 
                "iso-2022-jp", "euc-jp"
            ]
    
    @classmethod
    def get_chunk_size(cls, file_size_mb: float) -> int:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã«å¿œã˜ã¦é©åˆ‡ãªãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’è¿”ã™"""
        if file_size_mb <= cls.SMALL_FILE_MB:
            return cls.DEFAULT_CHUNK_SIZE
        elif file_size_mb <= cls.MEDIUM_FILE_MB:
            return cls.DEFAULT_CHUNK_SIZE
        else:
            return cls.LARGE_FILE_CHUNK_SIZE
    
    @classmethod
    def get_worker_count(cls, file_count: int) -> int:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã«å¿œã˜ã¦é©åˆ‡ãªãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’è¿”ã™"""
        return min(cls.MAX_WORKERS, max(1, file_count))


@dataclass
class DatabaseConfig:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š"""
    
    # SQLiteãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
    DB_FILENAME: str = "unified_database.db"
    BACKUP_PREFIX: str = "backup_"
    
    # SQLiteæœ€é©åŒ–è¨­å®š
    PRAGMA_SETTINGS: Dict[str, str] = None
    
    # ãƒ†ãƒ¼ãƒ–ãƒ«åè¨­å®š
    TABLE_MAPPING: Dict[str, str] = None
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®š
    AUTO_INDEX_COLUMNS: List[str] = None
    COMPOSITE_INDEXES: List[Dict[str, any]] = None
    
    def __post_init__(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š"""
        if self.PRAGMA_SETTINGS is None:
            self.PRAGMA_SETTINGS = {
                "journal_mode": "WAL",
                "synchronous": "NORMAL",
                "cache_size": "10000",
                "mmap_size": "268435456",
                "temp_store": "MEMORY",
                "page_size": "4096"
            }
        
        if self.TABLE_MAPPING is None:
            self.TABLE_MAPPING = {
                "PLM": "plm_item_plant_info",
                "WBS": "wbs_sekkei_jisseki",
                "BOM": "bom_mara_data",
                "PRODUCTION": "production_yotei",
                "INVENTORY": "inventory_teiryu"
            }
        
        if self.AUTO_INDEX_COLUMNS is None:
            self.AUTO_INDEX_COLUMNS = [
                "id", "date", "code", "item_code", 
                "plant_code", "created_at", "updated_at"
            ]
        
        if self.COMPOSITE_INDEXES is None:
            self.COMPOSITE_INDEXES = [
                {
                    "columns": ["date", "plant_code"],
                    "name": "idx_date_plant"
                },
                {
                    "columns": ["item_code", "plant_code"],
                    "name": "idx_item_plant"
                },
                {
                    "columns": ["created_at", "updated_at"],
                    "name": "idx_timestamps"
                }
            ]


@dataclass
class LoggingConfig:
    """ãƒ­ã‚°è¨­å®š"""
    
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«
    LOG_LEVEL: str = "INFO"
    
    # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
    LOG_FILENAME: str = "unified_system.log"
    ERROR_LOG_FILENAME: str = "errors.log"
    
    # ãƒ­ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    LOG_FORMAT: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    DATE_FORMAT: str = "%Y-%m-%d %H:%M:%S"
    
    # ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
    MAX_FILE_SIZE: str = "10MB"
    BACKUP_COUNT: int = 5
    
    # è©³ç´°ãƒ­ã‚°å‡ºåŠ›å¯¾è±¡
    DETAILED_MODULES: List[str] = None
    
    def __post_init__(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®è¨­å®š"""
        if self.DETAILED_MODULES is None:
            self.DETAILED_MODULES = [
                "sqlite_manager",
                "file_processor",
                "database_operations"
            ]


# ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã§ä½¿ç”¨ã™ã‚‹å®šæ•°
class SystemConstants:
    """ã‚·ã‚¹ãƒ†ãƒ å®šæ•°ã‚¯ãƒ©ã‚¹"""
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
    SYSTEM_VERSION: str = "1.0.0"
    SYSTEM_NAME: str = "çµ±åˆãƒ‡ãƒ¼ã‚¿æ›´æ–°å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ "
    
    # æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    DATE_FORMAT: str = "%Y-%m-%d"
    DATETIME_FORMAT: str = "%Y-%m-%d %H:%M:%S"
    TIMESTAMP_FORMAT: str = "%Y%m%d_%H%M%S"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­
    SUPPORTED_EXTENSIONS: Tuple[str, ...] = (".csv", ".txt", ".xlsx", ".xls")
    
    # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    ERROR_MESSAGES: Dict[str, str] = {
        "FILE_NOT_FOUND": "æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}",
        "ENCODING_ERROR": "ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’åˆ¤å®šã§ãã¾ã›ã‚“: {filepath}",
        "DATABASE_ERROR": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error}",
        "PROCESSING_ERROR": "ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error}",
        "MEMORY_ERROR": "ãƒ¡ãƒ¢ãƒªä¸è¶³ã«ã‚ˆã‚Šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
        "TIMEOUT_ERROR": "å‡¦ç†ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
    }
    
    # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    SUCCESS_MESSAGES: Dict[str, str] = {
        "FILE_PROCESSED": "ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ: {filepath}",
        "DATABASE_UPDATED": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸ: {table_name}",
        "BACKUP_CREATED": "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {backup_path}",
        "SYSTEM_INITIALIZED": "ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ"
    }


# ç’°å¢ƒå¤‰æ•°ã®å–å¾—
def get_env_variable(key: str, default: str = None) -> Optional[str]:
    """ç’°å¢ƒå¤‰æ•°ã‚’å–å¾—"""
    return os.getenv(key, default)


# è¨­å®šã®æ¤œè¨¼
def validate_configuration() -> List[str]:
    """è¨­å®šã®å¦¥å½“æ€§ã‚’æ¤œè¨¼ã—ã€å•é¡Œç‚¹ã‚’ãƒªã‚¹ãƒˆã§è¿”ã™"""
    issues = []
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
    paths = Paths()
    if not paths.BASE_DIR.exists():
        issues.append(f"ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {paths.BASE_DIR}")
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    config_file = paths.CONFIG_DIR / "database_config.yaml"
    if not config_file.exists():
        issues.append(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {config_file}")
    
    return issues


# åˆæœŸåŒ–å‡¦ç†
def initialize_system() -> bool:
    """ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
    try:
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        Paths.create_directories()
        
        # è¨­å®šæ¤œè¨¼
        issues = validate_configuration()
        if issues:
            print("è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™:")
            for issue in issues:
                print(f"  - {issue}")
            return False
        
        print(SystemConstants.SUCCESS_MESSAGES["SYSTEM_INITIALIZED"])
        return True
        
    except Exception as e:
        print(f"ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print(f"{SystemConstants.SYSTEM_NAME} v{SystemConstants.SYSTEM_VERSION}")
    print("=" * 50)
    
    # åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
    if initialize_system():
        print("âœ… ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–æˆåŠŸ")
        
        # è¨­å®šå€¤ã®è¡¨ç¤º
        print("\nğŸ“ ãƒ‘ã‚¹è¨­å®š:")
        paths = Paths()
        print(f"  ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {paths.BASE_DIR}")
        print(f"  ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {paths.DATA_DIR}")
        print(f"  ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {paths.LOGS_DIR}")
        
        print("\nğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³:")
        patterns = FilePatterns.get_all_patterns()
        for name, config in patterns.items():
            print(f"  {name}: {config['pattern']}")
        
        print("\nâš™ï¸  å‡¦ç†è¨­å®š:")
        process_config = ProcessConfig()
        print(f"  ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {process_config.DEFAULT_CHUNK_SIZE:,}")
        print(f"  æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {process_config.MAX_WORKERS}")
        print(f"  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {process_config.TIMEOUT_SECONDS}ç§’")
        
    else:
        print("âŒ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å¤±æ•—")

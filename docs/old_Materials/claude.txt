{
  `path`: `old_Materials`,
  `repo`: `claude-test`,
  `owner`: `k66-keroro`
}
ãƒ¬ã‚¹ãƒãƒ³ã‚¹

Error executing code: MCP error -32603: Not Found: Resource not found: Not Found


{
  `path`: `.`,
  `repo`: `claude-test`,
  `owner`: `k66-keroro`
}

[
  {
    "type": "file",
    "size": 1741,
    "name": "PROGRESS.md",
    "path": "PROGRESS.md",
    "sha": "03b70d7925b86c4c4200fd1705f255f43b845772",
    "url": "https://api.github.com/repos/k66-keroro/claude-test/contents/PROGRESS.md?ref=main",
    "git_url": "https://api.github.com/repos/k66-keroro/claude-test/git/blobs/03b70d7925b86c4c4200fd1705f255f43b845772",
    "html_url": "https://github.com/k66-keroro/claude-test/blob/main/PROGRESS.md",
    "download_url": "https://raw.githubusercontent.com/k66-keroro/claude-test/main/PROGRESS.md"
  },
  {
    "type": "file",
    "size": 39,
    "name": "README.md",
    "path": "README.md",
    "sha": "f4fee787417004ff1340e133c6f94cd7e895b76a",
    "url": "https://api.github.com/repos/k66-keroro/claude-test/contents/README.md?ref=main",
    "git_url": "https://api.github.com/repos/k66-keroro/claude-test/git/blobs/f4fee787417004ff1340e133c6f94cd7e895b76a",
    "html_url": "https://github.com/k66-keroro/claude-test/blob/main/README.md",
    "download_url": "https://raw.githubusercontent.com/k66-keroro/claude-test/main/README.md"
  },
  {
    "type": "file",
    "size": 3205,
    "name": "SPECIFICATION.md",
    "path": "SPECIFICATION.md",
    "sha": "e5eff85efe7c181b7665eee0b0ee8968d75d5dc5",
    "url": "https://api.github.com/repos/k66-keroro/claude-test/contents/SPECIFICATION.md?ref=main",
    "git_url": "https://api.github.com/repos/k66-keroro/claude-test/git/blobs/e5eff85efe7c181b7665eee0b0ee8968d75d5dc5",
    "html_url": "https://github.com/k66-keroro/claude-test/blob/main/SPECIFICATION.md",
    "download_url": "https://raw.githubusercontent.com/k66-keroro/claude-test/main/SPECIFICATION.md"
  },
  {
    "type": "dir",
    "size": 0,
    "name": "docs",
    "path": "docs",
    "sha": "e22c47582df95e8d325d91fcbe5b6017efb8a56c",
    "url": "https://api.github.com/repos/k66-keroro/claude-test/contents/docs?ref=main",
    "git_url": "https://api.github.com/repos/k66-keroro/claude-test/git/trees/e22c47582df95e8d325d91fcbe5b6017efb8a56c",
    "html_url": "https://github.com/k66-keroro/claude-test/tree/main/docs",
    "download_url": null
  },
  {
    "type": "file",
    "size": 11,
    "name": "test.txt",
    "path": "test.txt",
    "sha": "5e1c309dae7f45e0f39b1bf3ac3cd9db12e7d689",
    "url": "https://api.github.com/repos/k66-keroro/claude-test/contents/test.txt?ref=main",
    "git_url": "https://api.github.com/repos/k66-keroro/claude-test/git/blobs/5e1c309dae7f45e0f39b1bf3ac3cd9db12e7d689",
    "html_url": "https://github.com/k66-keroro/claude-test/blob/main/test.txt",
    "download_url": "https://raw.githubusercontent.com/k66-keroro/claude-test/main/test.txt"
  }
]

{
  `path`: `docs`,
  `repo`: `claude-test`,
  `owner`: `k66-keroro`
}

[
  {
    "type": "file",
    "size": 2292,
    "name": "PROJECT_STRUCTURE.md",
    "path": "docs/PROJECT_STRUCTURE.md",
    "sha": "76d19f4bf4bedb965b98cec177b4791457bea14d",
    "url": "https://api.github.com/repos/k66-keroro/claude-test/contents/docs/PROJECT_STRUCTURE.md?ref=main",
    "git_url": "https://api.github.com/repos/k66-keroro/claude-test/git/blobs/76d19f4bf4bedb965b98cec177b4791457bea14d",
    "html_url": "https://github.com/k66-keroro/claude-test/blob/main/docs/PROJECT_STRUCTURE.md",
    "download_url": "https://raw.githubusercontent.com/k66-keroro/claude-test/main/docs/PROJECT_STRUCTURE.md"
  },
  {
    "type": "dir",
    "size": 0,
    "name": "old_Materials",
    "path": "docs/old_Materials",
    "sha": "d0e11f4c1e92fb35e888be1c923ac2907d378de0",
    "url": "https://api.github.com/repos/k66-keroro/claude-test/contents/docs/old_Materials?ref=main",
    "git_url": "https://api.github.com/repos/k66-keroro/claude-test/git/trees/d0e11f4c1e92fb35e888be1c923ac2907d378de0",
    "html_url": "https://github.com/k66-keroro/claude-test/tree/main/docs/old_Materials",
    "download_url": null
  }
]

{
  `path`: `docs/old_Materials`,
  `repo`: `claude-test`,
  `owner`: `k66-keroro`
}

{
  `path`: `docs/PROJECT_STRUCTURE.md`,
  `repo`: `claude-test`,
  `owner`: `k66-keroro`
}


{
  "name": "PROJECT_STRUCTURE.md",
  "path": "docs/PROJECT_STRUCTURE.md",
  "sha": "76d19f4bf4bedb965b98cec177b4791457bea14d",
  "size": 2292,
  "url": "https://api.github.com/repos/k66-keroro/claude-test/contents/docs/PROJECT_STRUCTURE.md?ref=main",
  "html_url": "https://github.com/k66-keroro/claude-test/blob/main/docs/PROJECT_STRUCTURE.md",
  "git_url": "https://api.github.com/repos/k66-keroro/claude-test/git/blobs/76d19f4bf4bedb965b98cec177b4791457bea14d",
  "download_url": "https://raw.githubusercontent.com/k66-keroro/claude-test/main/docs/PROJECT_STRUCTURE.md",
  "type": "file",
  "content": "# æ¯æ—¥ã®ãƒ‡ãƒ¼ã‚¿æ›´æ–°å‡¦ç†åˆ·æ–°ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ\n\n## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦\næ¯æ—¥ã®ãƒ‡ãƒ¼ã‚¿æ›´æ–°å‡¦ç†ã‚’åŠ¹ç‡åŒ–ãƒ»è‡ªå‹•åŒ–ã™ã‚‹Pythoné…å¸ƒãƒ„ãƒ¼ãƒ«ã®é–‹ç™º\n\n## ğŸ“ æ¨å¥¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ \n```\ndaily-data-update-tool/\nâ”œâ”€â”€ README.md                 # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ãƒ»ä½¿ç”¨æ–¹æ³•\nâ”œâ”€â”€ SPECIFICATION.md          # è©³ç´°ä»•æ§˜æ›¸\nâ”œâ”€â”€ PROGRESS.md              # é€²æ—ç®¡ç†ãƒ»é–‹ç™ºãƒ­ã‚°\nâ”œâ”€â”€ INSTALLATION.md          # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †\nâ”œâ”€â”€ docs/                    # è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ\nâ”‚   â”œâ”€â”€ api-reference.md     # APIä»•æ§˜\nâ”‚   â”œâ”€â”€ user-guide.md        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¬ã‚¤ãƒ‰\nâ”‚   â””â”€â”€ developer-guide.md   # é–‹ç™ºè€…å‘ã‘ã‚¬ã‚¤ãƒ‰\nâ”œâ”€â”€ src/                     # ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰\nâ”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”œâ”€â”€ main.py             # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ\nâ”‚   â”œâ”€â”€ data_processor.py   # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯\nâ”‚   â”œâ”€â”€ config/             # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«\nâ”‚   â””â”€â”€ utils/              # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\nâ”œâ”€â”€ tests/                  # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰\nâ”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”œâ”€â”€ test_main.py\nâ”‚   â””â”€â”€ test_data_processor.py\nâ”œâ”€â”€ requirements.txt        # ä¾å­˜é–¢ä¿‚\nâ”œâ”€â”€ setup.py               # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸è¨­å®š\nâ”œâ”€â”€ .gitignore            # Gité™¤å¤–ãƒ•ã‚¡ã‚¤ãƒ«\nâ””â”€â”€ LICENSE               # ãƒ©ã‚¤ã‚»ãƒ³ã‚¹\n```\n\n## ğŸ“‹ ä½œæˆã™ã‚‹æ–‡æ›¸ã®å½¹å‰²\n\n### 1. README.md\n- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ¦‚è¦\n- ä¸»ãªæ©Ÿèƒ½\n- ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰\n- åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹\n\n### 2. SPECIFICATION.md\n- è©³ç´°ãªæ©Ÿèƒ½ä»•æ§˜\n- ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å›³\n- ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶\n- åˆ¶ç´„äº‹é …\n\n### 3. PROGRESS.md\n- é–‹ç™ºé€²æ—ã®è¨˜éŒ²\n- ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³\n- TODO ãƒªã‚¹ãƒˆ\n- å®Œäº†æ¸ˆã¿ã‚¿ã‚¹ã‚¯\n- ä»Šå¾Œã®è¨ˆç”»\n\n### 4. INSTALLATION.md\n- ç’°å¢ƒè¦ä»¶\n- ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †\n- åˆæœŸè¨­å®šæ–¹æ³•\n- ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°\n\n## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n1. æ—¢å­˜ã®mdãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ç¢ºèª\n2. é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªãƒ¼ã¸ã®åˆ†é¡\n3. GitHubãƒªãƒã‚¸ãƒˆãƒªã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n4. ç¶™ç¶šçš„ãªæ›´æ–°ä½“åˆ¶ã®æ§‹ç¯‰\n\n---\n\n**ä½œæˆæ—¥**: 2025å¹´6æœˆ23æ—¥\n**æ›´æ–°äºˆå®š**: æ—¢å­˜è³‡æ–™ç¢ºèªå¾Œã«å…·ä½“çš„ãªå†…å®¹ã§æ›´æ–°",
  "encoding": "base64",
  "_links": {
    "self": "https://api.github.com/repos/k66-keroro/claude-test/contents/docs/PROJECT_STRUCTURE.md?ref=main",
    "git": "https://api.github.com/repos/k66-keroro/claude-test/git/blobs/76d19f4bf4bedb965b98cec177b4791457bea14d",
    "html": "https://github.com/k66-keroro/claude-test/blob/main/docs/PROJECT_STRUCTURE.md"
  }
}


old_Materialsãƒ•ã‚©ãƒ«ãƒ€ã®ä¸»è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¾ã™ã€‚

{
  `path`: `docs/old_Materials/001_æ±ºå®š(Î¦Ï‰Î¦).md`,
  `repo`: `claude-test`,
  `owner`: `k66-keroro`
}

{
  "name": "001_æ±ºå®š(Î¦Ï‰Î¦).md",
  "path": "docs/old_Materials/001_æ±ºå®š(Î¦Ï‰Î¦).md",
  "sha": "48324f4b5ebeefc67ecd6abe5a432e05fcaf1e7e",
  "size": 1004,
  "url": "https://api.github.com/repos/k66-keroro/claude-test/contents/docs/old_Materials/001_%E6%B1%BA%E5%AE%9A(%CE%A6%CF%89%CE%A6).md?ref=main",
  "html_url": "https://github.com/k66-keroro/claude-test/blob/main/docs/old_Materials/001_%E6%B1%BA%E5%AE%9A(%CE%A6%CF%89%CE%A6).md",
  "git_url": "https://api.github.com/repos/k66-keroro/claude-test/git/blobs/48324f4b5ebeefc67ecd6abe5a432e05fcaf1e7e",
  "download_url": "https://raw.githubusercontent.com/k66-keroro/claude-test/main/docs/old_Materials/001_æ±ºå®š(Î¦Ï‰Î¦).md",
  "type": "file",
  "content": "`C:\\Projects_workspace\\03_unified_system\\\nâ”œâ”€â”€ config/                 # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«\nâ”‚   â”œâ”€â”€ constants.py        # ãƒ‘ã‚¹ãƒ»å®šæ•°ç®¡ç†\nâ”‚   â”œâ”€â”€ database_config.py  # DBæ¥ç¶šè¨­å®š\nâ”‚   â””â”€â”€ file_mapping.yaml   # ãƒ•ã‚¡ã‚¤ãƒ«-ãƒ†ãƒ¼ãƒ–ãƒ«å¯¾å¿œ\nâ”œâ”€â”€ src/                    # ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰\nâ”‚   â”œâ”€â”€ core/              # ã‚³ã‚¢æ©Ÿèƒ½\nâ”‚   â”‚   â”œâ”€â”€ sqlite_manager.py\nâ”‚   â”‚   â”œâ”€â”€ file_processor.py\nâ”‚   â”‚   â””â”€â”€ access_exporter.py\nâ”‚   â”œâ”€â”€ processors/        # ãƒ‡ãƒ¼ã‚¿å‡¦ç†\nâ”‚   â”‚   â”œâ”€â”€ sap_processors/\nâ”‚   â”‚   â””â”€â”€ transform_rules/\nâ”‚   â””â”€â”€ dashboard/         # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰\nâ”œâ”€â”€ data/                  # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\nâ”‚   â”œâ”€â”€ raw/              # ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆSAPå‡ºåŠ›ï¼‰\nâ”‚   â”œâ”€â”€ sqlite/           # SQLiteDB\nâ”‚   â””â”€â”€ access/           # Accessé…å¸ƒç”¨\nâ”œâ”€â”€ logs/                 # ãƒ­ã‚°\nâ””â”€â”€ tests/                # ãƒ†ã‚¹ãƒˆ`",
  "encoding": "base64",
  "_links": {
    "self": "https://api.github.com/repos/k66-keroro/claude-test/contents/docs/old_Materials/001_%E6%B1%BA%E5%AE%9A(%CE%A6%CF%89%CE%A6).md?ref=main",
    "git": "https://api.github.com/repos/k66-keroro/claude-test/git/blobs/48324f4b5ebeefc67ecd6abe5a432e05fcaf1e7e",
    "html": "https://github.com/k66-keroro/claude-test/blob/main/docs/old_Materials/001_%E6%B1%BA%E5%AE%9A(%CE%A6%CF%89%CE%A6).md"
  }
}

{
  `path`: `docs/old_Materials/20250620_è¨ˆç”»2_py.md`,
  `repo`: `claude-test`,
  `owner`: `k66-keroro`
}

{
  "name": "20250620_è¨ˆç”»2_py.md",
  "path": "docs/old_Materials/20250620_è¨ˆç”»2_py.md",
  "sha": "4b16af5d3176f9c49833b0805f1e633c1e98a03d",
  "size": 15910,
  "url": "https://api.github.com/repos/k66-keroro/claude-test/contents/docs/old_Materials/20250620_%E8%A8%88%E7%94%BB2_py.md?ref=main",
  "html_url": "https://github.com/k66-keroro/claude-test/blob/main/docs/old_Materials/20250620_%E8%A8%88%E7%94%BB2_py.md",
  "git_url": "https://api.github.com/repos/k66-keroro/claude-test/git/blobs/4b16af5d3176f9c49833b0805f1e633c1e98a03d",
  "download_url": "https://raw.githubusercontent.com/k66-keroro/claude-test/main/docs/old_Materials/20250620_è¨ˆç”»2_py.md",
  "type": "file",
  "content": "# config/constants.py\nfrom pathlib import Path\nfrom dataclasses import dataclass\nfrom typing import Dict, List\n\n@dataclass\nclass Paths:\n    \"\"\"ãƒ‘ã‚¹å®šæ•°ç®¡ç†\"\"\"\n    PROJECT_ROOT: Path = Path(r\"C:\\Projects_workspace\\03_unified_system\")\n    RAW_DATA: Path = PROJECT_ROOT / \"data\" / \"raw\"\n    SQLITE_DB: Path = PROJECT_ROOT / \"data\" / \"sqlite\" / \"main.db\"\n    ACCESS_OUTPUT: Path = PROJECT_ROOT / \"data\" / \"access\"\n    LOGS: Path = PROJECT_ROOT / \"logs\"\n    \n    def __post_init__(self):\n        \"\"\"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\"\"\"\n        for path in [self.RAW_DATA, self.SQLITE_DB.parent, self.ACCESS_OUTPUT, self.LOGS]:\n            path.mkdir(parents=True, exist_ok=True)\n\n@dataclass \nclass FilePatterns:\n    \"\"\"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©\"\"\"\n    SAP_FILES: Dict[str, str] = None\n    \n    def __post_init__(self):\n        self.SAP_FILES = {\n            \"PLM\": \"GetPLMItmPlntInfo_*.txt\",\n            \"WBS\": \"GetSekkeiWBSJisseki.txt\", \n            \"BOM\": \"MARA_DL.csv\",\n            \"SEISAN\": \"PP_DL_CSV_SEISAN_YOTEI.csv\",\n            \"ZAIKO\": \"dbo_æå‡ºç”¨_çµŒç†_æ»ç•™åœ¨åº«è³‡æ–™_é€šå¸¸.xlsx\"\n        }\n\n@dataclass\nclass ProcessConfig:\n    \"\"\"å‡¦ç†è¨­å®š\"\"\"\n    CHUNK_SIZE: int = 50000\n    MAX_WORKERS: int = 4\n    TIMEOUT_SECONDS: int = 300\n    ENCODING_LIST: List[str] = None\n    \n    def __post_init__(self):\n        self.ENCODING_LIST = ['utf-8', 'shift_jis', 'cp932', 'iso-2022-jp']\n\n# =============================================================================\n# src/core/sqlite_manager.py\nimport sqlite3\nimport pandas as pd\nimport logging\nfrom pathlib import Path\nfrom typing import Optional, List, Dict, Any\nfrom concurrent.futures import ThreadPoolExecutor\nimport time\n\nclass SQLiteManager:\n    \"\"\"SQLiteçµ±ä¸€ç®¡ç†ã‚¯ãƒ©ã‚¹\"\"\"\n    \n    def __init__(self, db_path: Path):\n        self.db_path = db_path\n        self.logger = self._setup_logger()\n        self._init_database()\n    \n    def _setup_logger(self) -> logging.Logger:\n        \"\"\"ãƒ­ã‚°è¨­å®š\"\"\"\n        logger = logging.getLogger(self.__class__.__name__)\n        if not logger.handlers:\n            handler = logging.FileHandler(\n                Paths().LOGS / f\"{self.__class__.__name__}.log\",\n                encoding='utf-8'\n            )\n            formatter = logging.Formatter(\n                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n            )\n            handler.setFormatter(formatter)\n            logger.addHandler(handler)\n            logger.setLevel(logging.INFO)\n        return logger\n    \n    def _init_database(self):\n        \"\"\"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–\"\"\"\n        with sqlite3.connect(self.db_path) as conn:\n            # æ€§èƒ½å‘ä¸Šè¨­å®š\n            conn.execute(\"PRAGMA journal_mode = WAL\")\n            conn.execute(\"PRAGMA synchronous = NORMAL\") \n            conn.execute(\"PRAGMA cache_size = 10000\")\n            conn.execute(\"PRAGMA temp_store = memory\")\n    \n    def bulk_insert_from_csv(self, file_path: Path, table_name: str, \n                           chunk_size: int = 50000, encoding: str = 'utf-8') -> bool:\n        \"\"\"CSVå¤§å®¹é‡ä¸€æ‹¬æŒ¿å…¥\"\"\"\n        start_time = time.time()\n        self.logger.info(f\"é–‹å§‹: {table_name} <- {file_path.name}\")\n        \n        try:\n            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•åˆ¤å®š\n            if encoding == 'auto':\n                encoding = self._detect_encoding(file_path)\n            \n            with sqlite3.connect(self.db_path) as conn:\n                # ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤ãƒ»ä½œæˆ\n                conn.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n                \n                total_rows = 0\n                for i, chunk in enumerate(pd.read_csv(file_path, \n                                                   chunksize=chunk_size,\n                                                   encoding=encoding,\n                                                   low_memory=False)):\n                    \n                    # åˆå›ã¯ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ\n                    if_exists = 'replace' if i == 0 else 'append'\n                    \n                    # ãƒ‡ãƒ¼ã‚¿å‹æœ€é©åŒ–\n                    chunk = self._optimize_dtypes(chunk)\n                    \n                    chunk.to_sql(table_name, conn, \n                               if_exists=if_exists, \n                               index=False, \n                               method='multi')\n                    \n                    total_rows += len(chunk)\n                    self.logger.info(f\"  å‡¦ç†ä¸­: {total_rows:,} rows\")\n                \n                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ\n                self._create_indexes(conn, table_name, chunk.columns)\n                \n            elapsed = time.time() - start_time\n            self.logger.info(f\"å®Œäº†: {table_name} ({total_rows:,} rows, {elapsed:.1f}s)\")\n            return True\n            \n        except Exception as e:\n            self.logger.error(f\"ã‚¨ãƒ©ãƒ¼: {table_name} - {str(e)}\")\n            return False\n    \n    def _detect_encoding(self, file_path: Path) -> str:\n        \"\"\"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•åˆ¤å®š\"\"\"\n        import chardet\n        \n        with open(file_path, 'rb') as f:\n            raw_data = f.read(100000)  # 100KBèª­ã¿å–ã‚Š\n            result = chardet.detect(raw_data)\n            encoding = result['encoding']\n            confidence = result['confidence']\n            \n        self.logger.info(f\"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åˆ¤å®š: {encoding} (ä¿¡é ¼åº¦: {confidence:.2f})\")\n        return encoding if confidence > 0.7 else 'shift_jis'\n    \n    def _optimize_dtypes(self, df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"ãƒ‡ãƒ¼ã‚¿å‹æœ€é©åŒ–\"\"\"\n        for col in df.columns:\n            if df[col].dtype == 'object':\n                # æ•°å€¤å¤‰æ›è©¦è¡Œ\n                try:\n                    # ã¾ãšæ•´æ•°å¤‰æ›\n                    if df[col].str.match(r'^-?\\d+$').all():\n                        df[col] = pd.to_numeric(df[col], downcast='integer')\n                    # æ¬¡ã«æµ®å‹•å°æ•°ç‚¹\n                    elif df[col].str.match(r'^-?\\d*\\.?\\d+$').all():\n                        df[col] = pd.to_numeric(df[col], downcast='float')\n                except:\n                    pass\n            elif df[col].dtype in ['int64', 'float64']:\n                df[col] = pd.to_numeric(df[col], downcast='integer' if 'int' in str(df[col].dtype) else 'float')\n        \n        return df\n    \n    def _create_indexes(self, conn: sqlite3.Connection, table_name: str, columns: List[str]):\n        \"\"\"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ\"\"\"\n        # ä¸»è¦ã‚«ãƒ©ãƒ ã®æ¨å®šã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ\n        key_patterns = ['id', 'code', 'key', 'no', 'ç•ªå·', 'ã‚³ãƒ¼ãƒ‰']\n        \n        for col in columns:\n            col_lower = col.lower()\n            if any(pattern in col_lower for pattern in key_patterns):\n                try:\n                    idx_name = f\"idx_{table_name}_{col.replace(' ', '_')}\"\n                    conn.execute(f\"CREATE INDEX IF NOT EXISTS {idx_name} ON {table_name} ({col})\")\n                    self.logger.info(f\"  ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ: {idx_name}\")\n                except Exception as e:\n                    self.logger.warning(f\"  ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå¤±æ•—: {col} - {str(e)}\")\n    \n    def export_to_access_format(self, table_name: str, output_path: Path) -> bool:\n        \"\"\"Accessäº’æ›å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\"\"\"\n        try:\n            with sqlite3.connect(self.db_path) as conn:\n                df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n                \n                # Accessäº’æ›ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›\n                for col in df.columns:\n                    if df[col].dtype == 'object':\n                        # æ–‡å­—åˆ—ã¯255æ–‡å­—åˆ¶é™\n                        df[col] = df[col].astype(str).str[:255]\n                    elif 'datetime' in str(df[col].dtype):\n                        # æ—¥ä»˜å½¢å¼çµ±ä¸€\n                        df[col] = pd.to_datetime(df[col], errors='coerce')\n                \n                # CSVå‡ºåŠ›ï¼ˆAccesså–ã‚Šè¾¼ã¿ç”¨ï¼‰\n                df.to_csv(output_path, index=False, encoding='shift_jis')\n                self.logger.info(f\"Accessç”¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {output_path}\")\n                return True\n                \n        except Exception as e:\n            self.logger.error(f\"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}\")\n            return False\n    \n    def get_table_info(self, table_name: str) -> Dict[str, Any]:\n        \"\"\"ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±å–å¾—\"\"\"\n        with sqlite3.connect(self.db_path) as conn:\n            cursor = conn.cursor()\n            \n            # è¡Œæ•°\n            cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n            row_count = cursor.fetchone()[0]\n            \n            # ã‚«ãƒ©ãƒ æƒ…å ±\n            cursor.execute(f\"PRAGMA table_info({table_name})\")\n            columns = cursor.fetchall()\n            \n            # ã‚µã‚¤ã‚ºæƒ…å ±\n            cursor.execute(f\"SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size()\")\n            db_size = cursor.fetchone()[0]\n            \n            return {\n                'row_count': row_count,\n                'columns': columns,\n                'db_size_mb': db_size / 1024 / 1024\n            }\n\n# =============================================================================\n# src/core/file_processor.py\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport glob\nfrom typing import List, Tuple\n\nclass FileProcessor:\n    \"\"\"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†çµ±åˆã‚¯ãƒ©ã‚¹\"\"\"\n    \n    def __init__(self):\n        self.paths = Paths()\n        self.config = ProcessConfig()\n        self.sqlite_mgr = SQLiteManager(self.paths.SQLITE_DB)\n        self.logger = self._setup_logger()\n    \n    def _setup_logger(self) -> logging.Logger:\n        logger = logging.getLogger(self.__class__.__name__)\n        if not logger.handlers:\n            handler = logging.FileHandler(\n                self.paths.LOGS / f\"{self.__class__.__name__}.log\",\n                encoding='utf-8'\n            )\n            formatter = logging.Formatter(\n                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n            )\n            handler.setFormatter(formatter)\n            logger.addHandler(handler)\n            logger.setLevel(logging.INFO)\n        return logger\n    \n    def process_all_files(self) -> Dict[str, bool]:\n        \"\"\"å…¨ãƒ•ã‚¡ã‚¤ãƒ«ä¸€æ‹¬å‡¦ç†\"\"\"\n        start_time = time.time()\n        self.logger.info(\"=== ãƒ•ã‚¡ã‚¤ãƒ«ä¸€æ‹¬å‡¦ç†é–‹å§‹ ===\")\n        \n        # å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—\n        file_tasks = self._get_file_tasks()\n        results = {}\n        \n        # ä¸¦è¡Œå‡¦ç†å®Ÿè¡Œ\n        with ThreadPoolExecutor(max_workers=self.config.MAX_WORKERS) as executor:\n            future_to_task = {\n                executor.submit(self._process_single_file, task): task \n                for task in file_tasks\n            }\n            \n            for future in as_completed(future_to_task):\n                task = future_to_task[future]\n                try:\n                    result = future.result(timeout=self.config.TIMEOUT_SECONDS)\n                    results[task['table_name']] = result\n                except Exception as e:\n                    self.logger.error(f\"ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {task['file_path']} - {str(e)}\")\n                    results[task['table_name']] = False\n        \n        # çµæœé›†è¨ˆ\n        success_count = sum(results.values())\n        total_count = len(results)\n        elapsed = time.time() - start_time\n        \n        self.logger.info(f\"=== å‡¦ç†å®Œäº†: {success_count}/{total_count} æˆåŠŸ ({elapsed:.1f}s) ===\")\n        return results\n    \n    def _get_file_tasks(self) -> List[Dict[str, Any]]:\n        \"\"\"å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ä½œæˆ\"\"\"\n        tasks = []\n        patterns = FilePatterns().SAP_FILES\n        \n        for key, pattern in patterns.items():\n            file_paths = list(self.paths.RAW_DATA.glob(pattern))\n            for file_path in file_paths:\n                if file_path.is_file():\n                    tasks.append({\n                        'file_path': file_path,\n                        'table_name': f\"{key}_{file_path.stem}\".lower(),\n                        'type': key\n                    })\n        \n        self.logger.info(f\"å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(tasks)} ä»¶\")\n        return tasks\n    \n    def _process_single_file(self, task: Dict[str, Any]) -> bool:\n        \"\"\"å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†\"\"\"\n        file_path = task['file_path']\n        table_name = task['table_name']\n        \n        # ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥åˆ¥å‡¦ç†\n        if file_path.suffix.lower() == '.csv':\n            return self.sqlite_mgr.bulk_insert_from_csv(\n                file_path, table_name, \n                chunk_size=self.config.CHUNK_SIZE,\n                encoding='auto'\n            )\n        elif file_path.suffix.lower() in ['.txt']:\n            # TXTãƒ•ã‚¡ã‚¤ãƒ«ã¯CSVã¨ã—ã¦å‡¦ç†ï¼ˆåŒºåˆ‡ã‚Šæ–‡å­—è‡ªå‹•åˆ¤å®šï¼‰\n            return self._process_txt_file(file_path, table_name)\n        elif file_path.suffix.lower() in ['.xlsx', '.xls']:\n            return self._process_excel_file(file_path, table_name)\n        else:\n            self.logger.warning(f\"æœªå¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {file_path}\")\n            return False\n    \n    def _process_txt_file(self, file_path: Path, table_name: str) -> bool:\n        \"\"\"TXTãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼ˆåŒºåˆ‡ã‚Šæ–‡å­—è‡ªå‹•åˆ¤å®šï¼‰\"\"\"\n        try:\n            # åŒºåˆ‡ã‚Šæ–‡å­—åˆ¤å®š\n            with open(file_path, 'r', encoding='shift_jis') as f:\n                first_line = f.readline()\n                \n            # åŒºåˆ‡ã‚Šæ–‡å­—å€™è£œ\n            separators = ['\\t', ',', '|', ' ']\n            best_sep = '\\t'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ\n            max_cols = 0\n            \n            for sep in separators:\n                cols = len(first_line.split(sep))\n                if cols > max_cols:\n                    max_cols = cols\n                    best_sep = sep\n            \n            # pandasã§èª­ã¿è¾¼ã¿ã€SQLiteã«ä¿å­˜\n            df = pd.read_csv(file_path, sep=best_sep, encoding='shift_jis')\n            \n            with sqlite3.connect(self.sqlite_mgr.db_path) as conn:\n                df.to_sql(table_name, conn, if_exists='replace', index=False)\n            \n            self.logger.info(f\"TXTå‡¦ç†å®Œäº†: {table_name} ({len(df)} rows)\")\n            return True\n            \n        except Exception as e:\n            self.logger.error(f\"TXTå‡¦ç†ã‚¨ãƒ©ãƒ¼: {file_path} - {str(e)}\")\n            return False\n    \n    def _process_excel_file(self, file_path: Path, table_name: str) -> bool:\n        \"\"\"Excelãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†\"\"\"\n        try:\n            # å…¨ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿\n            excel_file = pd.ExcelFile(file_path)\n            \n            with sqlite3.connect(self.sqlite_mgr.db_path) as conn:\n                for sheet_name in excel_file.sheet_names:\n                    df = pd.read_excel(file_path, sheet_name=sheet_name)\n                    sheet_table_name = f\"{table_name}_{sheet_name}\".lower()\n                    df.to_sql(sheet_table_name, conn, if_exists='replace', index=False)\n                    self.logger.info(f\"Excelå‡¦ç†: {sheet_table_name} ({len(df)} rows)\")\n            \n            return True\n            \n        except Exception as e:\n            self.logger.error(f\"Excelå‡¦ç†ã‚¨ãƒ©ãƒ¼: {file_path} - {str(e)}\")\n            return False\n\n# =============================================================================\n# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ\nif __name__ == \"__main__\":\n    # è¨­å®šåˆæœŸåŒ–\n    paths = Paths()\n    \n    # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Ÿè¡Œ\n    processor = FileProcessor()\n    results = processor.process_all_files()\n    \n    # çµæœè¡¨ç¤º\n    print(\"\\n=== å‡¦ç†çµæœ ===\")\n    for table, success in results.items():\n        status = \"âœ… æˆåŠŸ\" if success else \"âŒ å¤±æ•—\"\n        print(f\"{table}: {status}\")\n    \n    print(f\"\\næˆåŠŸç‡: {sum(results.values())}/{len(results)} ({sum(results.values())/len(results)*100:.1f}%)\")",
  "encoding": "base64",
  "_links": {
    "self": "https://api.github.com/repos/k66-keroro/claude-test/contents/docs/old_Materials/20250620_%E8%A8%88%E7%94%BB2_py.md?ref=main",
    "git": "https://api.github.com/repos/k66-keroro/claude-test/git/blobs/4b16af5d3176f9c49833b0805f1e633c1e98a03d",
    "html": "https://github.com/k66-keroro/claude-test/blob/main/docs/old_Materials/20250620_%E8%A8%88%E7%94%BB2_py.md"
  }
}


